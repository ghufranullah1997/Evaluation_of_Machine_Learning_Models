{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Ghufran Ullah\n",
    "\n",
    "Student number: 2411327\n",
    "\n",
    "Student email: ghufran.u.ullah@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, what is the correct way to perform cross-validation in the given scenario, and why the correct cross-validation method will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 19 February 2025 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have already made laboratory experiments to measure the affinities between some proteins and drug molecules.\n",
    "\n",
    "My colleague is working on another set of proteins, and the objectives of his project are similar to mine. He has recently discovered thousands of new potential drug molecules. He asked me if I could find the pairs that have the strongest affinities among his proteins and drug molecules. Obviously I do not have the resources to measure all the possible pairs in my laboratory, so I need to prioritise. I decided to do this with the help of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had already made in the laboratory with my proteins and drug molecules. They comprise of 77 target proteins and 59 drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of my colleague's proteins and drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether it would be a waste of my resources if I were to use my model any further.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "# Remember to provide comprehensive and precise arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did the estimation described in the letter fail?**\n",
    "\n",
    "**Answer:** The leave-one-out cross-validation (LOOCV) used by the researcher failed because it did not account for the structure of the data, which lead to data leakage. Since the following dataset consists of protein-drug pairs, removing only one pair at a time means that the same proteins and drugs still appear in both the training and validation sets. This will allow the K-Nearest Neighbors (KNN) model to rely on previously seen proteins or drugs data samples for making predictions, which is creating an illusion of high accuracy. The model does not truly generalize but instead memorizes affinity values for specific proteins and drugs, which explains the exceptionally high cross-validation score (C-index > 90%). However, when the model was applied to an entirely new dataset with unseen proteins and drugs, its predictions turned out to be unreliable. This failure shows that the model was overfitting to the known proteins and drugs in the dataset rather than learning a general pattern for predicting affinities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How should leave-one-out cross-validation be performed in the given scenario and why?**\n",
    "\n",
    "**Answer** To obtain a better and reliable estimate of generalization performance, I think cross-validation should be designed in such a way that ensures no proteins or drugs in the validation set appear in the training set. Instead of standard LOOCV, we  could use Leave-Protein-Out (LPO) cross-validation or Leave-Pair-Out (LPO) cross-validation. In Leave-Protein-Out CV, each fold removes all pairs associated with a specific protein (or drug) so that the model cannot rely on prior knowledge of that protein when making predictions. Similarly, Leave-Pair-Out CV removes specific protein-drug interactions across different folds to avoid any overlap. These approaches prevent data leakage and ensure that the model is tested only on truly unseen data. An alternative method could be Grouped K-Fold Cross-Validation, where proteins or drugs are grouped together and assigned to distinct folds, ensuring no mixing between training and validation sets. These techniques provide a more realistic estimate of how well the model would perform in a real-world scenario where it must predict affinities for entirely new proteins and drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why will the correct cross-validation method give a reliable estimate of generalization performance?**\n",
    "\n",
    "**Answer:** I think the correct cross-validation method will provide a more accurate estimate of generalization performance because it eliminates possibility of data leakage and prevents overfitting to specific proteins or drugs. When proteins and drugs are removed entirely from the training set before being tested, the given model is forced to make predictions based on general patterns rather than memorized information gained during training. This will simulate the real-world challenge of predicting affinities for unseen protein-drug pairs, which is the main goal of the research. I think by ensuring that validation data is truly independent from training data, the revised approach will yield performance metrics that reflect how well the model will work on new experimental data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_c_index(y_true, y_pred):\n",
    "    \"\"\"Compute the Concordance Index (C-Index) to evaluate model performance.\"\"\"\n",
    "    n = 0 # Total number of comparable pairs\n",
    "    h_sum = 0.0 # Count of correctly ranked pairs\n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(i + 1, len(y_true)):\n",
    "            if y_true[i] != y_true[j]: # Consider only pairs with different true values\n",
    "                n += 1\n",
    "                h_sum += int((y_pred[i] > y_pred[j]) == (y_true[i] > y_true[j]))\n",
    "    return h_sum / n if n > 0 else 0.5 # Return C-Index value, defaulting to 0.5 if no valid pairs exist\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Evaluate the model using Pearson correlation and C-Index.\"\"\"\n",
    "    pearson_corr, _ = pearsonr(y_true, y_pred)\n",
    "    c_index = calculate_c_index(y_true, y_pred)\n",
    "    return {\n",
    "        \"Pearson Correlation\": pearson_corr,\n",
    "        \"C-Index\": c_index\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(\"input.data\", delim_whitespace=True, header=None)\n",
    "output_data = pd.read_csv(\"output.data\", delim_whitespace=True, header=None)\n",
    "pairs_data = pd.read_csv(\"pairs.data\", delim_whitespace=True, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759222</td>\n",
       "      <td>0.709585</td>\n",
       "      <td>0.253151</td>\n",
       "      <td>0.421082</td>\n",
       "      <td>0.727780</td>\n",
       "      <td>0.404487</td>\n",
       "      <td>0.709027</td>\n",
       "      <td>0.242963</td>\n",
       "      <td>0.407292</td>\n",
       "      <td>0.379971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838616</td>\n",
       "      <td>0.165050</td>\n",
       "      <td>0.515334</td>\n",
       "      <td>0.332678</td>\n",
       "      <td>0.577533</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.463608</td>\n",
       "      <td>0.538938</td>\n",
       "      <td>0.460883</td>\n",
       "      <td>0.345251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.304720</td>\n",
       "      <td>0.688257</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.151878</td>\n",
       "      <td>0.830755</td>\n",
       "      <td>0.270656</td>\n",
       "      <td>0.705392</td>\n",
       "      <td>0.186120</td>\n",
       "      <td>0.085594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472762</td>\n",
       "      <td>0.730013</td>\n",
       "      <td>0.639373</td>\n",
       "      <td>0.445218</td>\n",
       "      <td>0.455680</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.308432</td>\n",
       "      <td>0.079023</td>\n",
       "      <td>0.603089</td>\n",
       "      <td>0.197008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.737867</td>\n",
       "      <td>0.236079</td>\n",
       "      <td>0.905987</td>\n",
       "      <td>0.163612</td>\n",
       "      <td>0.801455</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.393999</td>\n",
       "      <td>0.522067</td>\n",
       "      <td>0.411352</td>\n",
       "      <td>0.781861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595468</td>\n",
       "      <td>0.582292</td>\n",
       "      <td>0.836193</td>\n",
       "      <td>0.281514</td>\n",
       "      <td>0.791790</td>\n",
       "      <td>0.081695</td>\n",
       "      <td>0.583450</td>\n",
       "      <td>0.422539</td>\n",
       "      <td>0.076437</td>\n",
       "      <td>0.299662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406913</td>\n",
       "      <td>0.607740</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.888679</td>\n",
       "      <td>0.150347</td>\n",
       "      <td>0.598991</td>\n",
       "      <td>0.130108</td>\n",
       "      <td>0.465818</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.906878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453880</td>\n",
       "      <td>0.311799</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.563793</td>\n",
       "      <td>0.727767</td>\n",
       "      <td>0.172686</td>\n",
       "      <td>0.908368</td>\n",
       "      <td>0.786892</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.666388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697707</td>\n",
       "      <td>0.432565</td>\n",
       "      <td>0.650329</td>\n",
       "      <td>0.886065</td>\n",
       "      <td>0.328660</td>\n",
       "      <td>0.576926</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.080463</td>\n",
       "      <td>0.131349</td>\n",
       "      <td>0.913496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583892</td>\n",
       "      <td>0.444141</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.110690</td>\n",
       "      <td>0.420770</td>\n",
       "      <td>0.250148</td>\n",
       "      <td>0.196350</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.166715</td>\n",
       "      <td>0.919720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.759222  0.709585  0.253151  0.421082  0.727780  0.404487  0.709027   \n",
       "1  0.034584  0.304720  0.688257  0.296396  0.151878  0.830755  0.270656   \n",
       "2  0.737867  0.236079  0.905987  0.163612  0.801455  0.789823  0.393999   \n",
       "3  0.406913  0.607740  0.235365  0.888679  0.150347  0.598991  0.130108   \n",
       "4  0.697707  0.432565  0.650329  0.886065  0.328660  0.576926  0.523100   \n",
       "\n",
       "         7         8         9   ...        57        58        59        60  \\\n",
       "0  0.242963  0.407292  0.379971  ...  0.838616  0.165050  0.515334  0.332678   \n",
       "1  0.705392  0.186120  0.085594  ...  0.472762  0.730013  0.639373  0.445218   \n",
       "2  0.522067  0.411352  0.781861  ...  0.595468  0.582292  0.836193  0.281514   \n",
       "3  0.465818  0.799953  0.906878  ...  0.453880  0.311799  0.534668  0.563793   \n",
       "4  0.080463  0.131349  0.913496  ...  0.583892  0.444141  0.249423  0.110690   \n",
       "\n",
       "         61        62        63        64        65        66  \n",
       "0  0.577533  0.678125  0.463608  0.538938  0.460883  0.345251  \n",
       "1  0.455680  0.090737  0.308432  0.079023  0.603089  0.197008  \n",
       "2  0.791790  0.081695  0.583450  0.422539  0.076437  0.299662  \n",
       "3  0.727767  0.172686  0.908368  0.786892  0.790459  0.666388  \n",
       "4  0.420770  0.250148  0.196350  0.427255  0.166715  0.919720  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows to confirm successful loading\n",
    "input_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.733933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.569419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.832588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.389664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.725953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.733933\n",
       "1  0.569419\n",
       "2  0.832588\n",
       "3  0.389664\n",
       "4  0.725953"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows to confirm successful loading\n",
    "\n",
    "output_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D40</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D31</td>\n",
       "      <td>T64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D6</td>\n",
       "      <td>T58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D56</td>\n",
       "      <td>T49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D20</td>\n",
       "      <td>T28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  D40   T2\n",
       "1  D31  T64\n",
       "2   D6  T58\n",
       "3  D56  T49\n",
       "4  D20  T28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows to confirm successful loading\n",
    "pairs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement and run the requested cross-validation. Report and interpret its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted to see and implementing Leave-Pair-Out Cross-Validation\n",
    "def perform_optimized_leave_pair_out(X, y, pairs, sample_fraction=0.05):\n",
    "    \"\"\"Perform Leave-Pair-Out cross-validation with randomized subsampling for efficiency.\n",
    "    Since LPO is computationally expensive, we use subsampling to reduce the number of evaluated pairs.\n",
    "    Instead of evaluating all possible pairs, we randomly sample a fraction of them, significantly improving efficiency.\n",
    "    This maintains representative evaluation while making the process more practical for large datasets.\n",
    "    \"\"\"\n",
    "    predictions = np.zeros(len(y))\n",
    "    \n",
    "    pair_indices = list(combinations(range(len(y)), 2))\n",
    "    sampled_pairs = random.sample(pair_indices, int(len(pair_indices) * sample_fraction))  # Subsample pairs\n",
    "    \n",
    "    for idx1, idx2 in sampled_pairs:\n",
    "        train_idx = [i for i in range(len(y)) if i not in (idx1, idx2)]\n",
    "        test_idx = [idx1, idx2]\n",
    "        \n",
    "        model = KNeighborsRegressor(n_neighbors=10)\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        predictions[test_idx] = model.predict(X.iloc[test_idx])\n",
    "    \n",
    "    return evaluate_model(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Leave-Pair-Out Cross-Validation Results: {'Pearson Correlation': 0.8687611484332883, 'C-Index': 0.8302255639097744}\n"
     ]
    }
   ],
   "source": [
    "cv_lpo_results = perform_optimized_leave_pair_out(X, y, pairs_data, sample_fraction=0.05)\n",
    "print(\"Optimized Leave-Pair-Out Cross-Validation Results:\", cv_lpo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Grouped Validation\n",
    "def perform_grouped_cross_validation(X, y, groups, n_splits=5):\n",
    "    \"\"\"Perform grouped k-fold cross-validation ensuring no data leakage.\n",
    "    This method ensures that all data points related to a specific group (e.g., a protein)\n",
    "    are kept together in either the training or test set, avoiding information leakage.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    predictions = np.zeros(len(y))\n",
    "    \n",
    "    for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "        model = KNeighborsRegressor(n_neighbors=10)\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        predictions[test_idx] = model.predict(X.iloc[test_idx])\n",
    "    \n",
    "    return evaluate_model(y, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features, target, and groups (proteins as groups)\n",
    "X = input_data\n",
    "y = output_data[0]\n",
    "groups = pairs_data[1]  # Assuming proteins are in column index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped K-Fold Cross-Validation Results: {'Pearson Correlation': 0.8104783532220297, 'C-Index': 0.7942606516290727}\n"
     ]
    }
   ],
   "source": [
    "# Run Grouped K-Fold cross-validation and report results\n",
    "cv_grouped_results = perform_grouped_cross_validation(X, y, groups)\n",
    "print(\"Grouped K-Fold Cross-Validation Results:\", cv_grouped_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implications and Interpretations of Results**\n",
    "\n",
    "The cross-validation results indicate that the model has a Pearson correlation of 0.8105, showing a strong positive relationship between predicted and actual affinity values, and a Concordance Index (C-Index) of 0.7943, which suggests that the model is reasonably good at ranking protein-drug pairs based on binding strength. Compared to the previous overoptimistic estimation (~90% C-Index) caused by data leakage in previous case, the new results provide a more realistic assessment of the model's generalization ability. While the model can be useful for prioritizing strong affinity pairs, it should not be blindly trusted for definitive predictions without further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
